---
title: "Internship: first try"
output: html_notebook
author: Sophie Tascedda
date: "`r Sys.Date()`"
params:
  num_regions: "15"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading libraries 
```{r}
library(CovRegFC)
library(cowplot)
library(ggplot2)
library(reshape2)
library(magrittr)
library(stringr)
library(devtools)
library(rstan)
library(abind)
library(BatchJobs)
library(reshape2)
library(rethinking)
library(cap)
library(dplyr)
params
```

## Loading HCP (Human Connectome Project) data

Load subject info
```{r}
subject_info = read.csv("data/HCP_PTN820/sample_info.csv")
subject_info = subject_info[,c(
  "Subject",
  "Age",
  "Gender",
  "Acquisition",
  "PSQI_AmtSleep", # amount of sleep in hours
  "PSQI_Score" # Pittsburgh Sleep Quality Index (PSQI) Completed
  )] 
```

Define two groups: short and conventional sleepers
```{r}
sleep_duration = rep("undefined",nrow(subject_info))
sleep_duration[subject_info$PSQI_AmtSleep <= 6] = "short"
sleep_duration[(subject_info$PSQI_AmtSleep >= 7) & (subject_info$PSQI_AmtSleep <= 9)] = "conventional"
subject_info$sleep_duration = factor(sleep_duration)
table(subject_info$sleep_duration)
str(subject_info)
```
Load timeseries

```{r}
num_regions = as.integer(params$num_regions)
num_regions
channel_names = paste0("R",1:num_regions)
path = paste0("data/HCP_PTN820/node_timeseries/3T_HCP820_MSMAll_d",num_regions,"_ts2")
file_names = list.files(path = path,pattern = ".txt")
file_subject_ids = strsplit(file_names,split = ".txt") %>% unlist
ts = lapply(file_subject_ids,function(Subject) {
  print(paste("reading subject:",Subject))
  full_path = paste0(path,"/",Subject,".txt")
  timeseries = read.csv(full_path,header = FALSE,sep = " ")
  timeseries$Subject = Subject
  timeseries
}) %>% do.call(rbind,.) %>% data.frame
names(ts)[1:num_regions] = channel_names
```
Merge timeseries and subject info, and create 2 groups: "short" sleepers and "conventional" sleepers
```{r}
ts_subject_info = merge(ts,subject_info,by = "Subject")
ts_short = subset(ts_subject_info,sleep_duration=="short")
ts_short$timepoint = rep(1:(nrow(ts_short)/4),4)
ts_conventional = subset(ts_subject_info,sleep_duration=="conventional")
ts_conventional$timepoint = rep(1:(nrow(ts_conventional)/4),4)
```

## Generate our Y and X:

Short sleepers
```{r}
short_ids=unique(ts_short$Subject)
short_subj=subset(subject_info,sleep_duration=="short")
short_subj <- short_subj[short_subj$Subject %in% short_ids, ]
X_short_subj<-short_subj[order(short_subj$Subject),]
Y_short <- lapply(split(ts_short,ts_short$Subject), "[", TRUE, -c(17:24))
Y_short <- lapply(Y_short, "[", TRUE, -c(1))

```

Conventional sleepers
```{r}
conventional_ids=unique(ts_conventional$Subject)
conventional_subj=subset(subject_info,sleep_duration=="conventional")
conventional_subj <- conventional_subj[conventional_subj$Subject %in% conventional_ids, ]
X_conv_subj<-conventional_subj[order(conventional_subj$Subject),]
Y_conv <- lapply(split(ts_conventional,ts_conventional$Subject), "[", TRUE, -c(17:24))
Y_conv <- lapply(Y_conv, "[", TRUE, -c(1))
```


Select 1 covariate (here "PSQI:Score") and convert Y and X to matrices (required by capReg)
```{r}
X_short_subset<-subset(X_short_subj, select="PSQI_Score")
X_short_subset<-cbind(inter = 1, X_short_subset)

X_short_subset<-data.matrix(X_short_subset)
Y_short<-lapply(Y_short, function(x) data.matrix(x))
```
```{r}
X_conv_subset<-subset(X_conv_subj, select="PSQI_Score")
X_conv_subset<-cbind(inter = 1, X_conv_subset)

X_conv_subset<-data.matrix(X_conv_subset)
Y_conv<-lapply(Y_conv, function(x) data.matrix(x))
```
Center Y
```{r}
Y_c_short<- lapply(Y_short, function(x) scale(x,center = TRUE, scale = FALSE))
Y_c_conv<- lapply(Y_conv, function(x) scale(x,center = TRUE, scale = FALSE))
```
## Fit capReg

Fit of capReg, using CAP algorithm

```{r fitting cap}
fit_cap_short<-capReg(Y_c_short,X_short_subset,method="CAP")
fit_cap_conv<-capReg(Y_c_conv,X_conv_subset,method = "CAP")
```

```{r}
fit_cap_short$beta

fit_cap_conv$beta
```
Fit of capReg, using CAP-C algorithm
```{r}
fit_cap_C_short<-capReg(Y_c_short,X_short_subset,method="CAP-C")
fit_cap_C_conv<-capReg(Y_c_conv,X_conv_subset,method = "CAP-C")
```

```{r}
fit_cap_C_short$beta

fit_cap_C_conv$beta
```


## Average sample covariance matrix per group of sleepers

```{r}
source("sample_covariance.R")
s_cov_short = sample_covariance(ts_subject_info,"sleep_duration","short")
s_cov_conventional = sample_covariance(ts_subject_info,"sleep_duration","conventional")
```

## Covariance forcasting

Getting the Inverse of gamma*gamma' 

```{r}
source("gamma_inv.R")
gg_inv_s<-gamma_inv(fit_cap_C_short$gamma)
gg_inv_c<-gamma_inv(fit_cap_C_conv$gamma)
```

COVARIANCE MATRIX SUBJ_1, SLEEPERS (original data)

```{r}
source("cov_pred_subj.R")
sig_hat_sj1<-cov_pred_subj(fit_cap_C_short$gamma,fit_cap_C_short$beta,X_short_subset,gg_inv_s)
```


Next steps:
- Ricava per ogni soggetto (sia in short che in conventional) la matrice di covarianza. Come? Sample covariance.
- Poi, make prediction per cov. matrix usando la formula qui sopra. PiÃ¹ in dettaglio, fai prediction sulla matrice di cov. per ogni soggetto usando unseen X values.

Sample covariance

```{r}
t<-Y_c_short[[1]]
```



ricavare elementi unici di x tra short e conventional
```{r}
unique(X_short_subj$PSQI_Score)%>%sort(decreasing = FALSE)
unique(X_conv_subj$PSQI_Score)%>%sort(decreasing = FALSE)
```
```{r}
a<-temp_s%*%c_short3$gamma
b<-exp(c_short3$beta[1]+X_short_subset[1,2]*c_short3$beta[2])
c<-c_short3$gamma%*%temp_s
sig_hat_s1<-a*b*c
```


























Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
