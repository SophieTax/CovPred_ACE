---
title: "Internship: exploring causal inference in the context of brain connectivity "
output: html_notebook
author: Sophie Tascedda
date: "`r Sys.Date()`"
params:
  num_regions: "15"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Investigating how we could combine causal inference
frameworks from social sciences and discovery frameworks
from machine learning to improve the statistical efficiency of
currently applied neuroimaging techniques.


## Loading libraries 
```{r}
library(CovRegFC)
library(cowplot)
library(ggplot2)
library(reshape2)
library(magrittr)
library(stringr)
library(devtools)
library(rstan)
library(abind)
library(BatchJobs)
library(reshape2)
library(rethinking)
library(cap)
library(dplyr)
params
```

## Loading HCP (Human Connectome Project) data
Analysis based on data from the WU-Minn HCP 1200 Subjects Data Release with four complete rfMRI runs (with 100% of collected time points).

Load subject info
```{r}
subject_info = read.csv("data/HCP_PTN820/sample_info.csv")
subject_info = subject_info[,c(
  "Subject",
  "Age",
  "Gender",
  "Acquisition",
  "PSQI_AmtSleep", # amount of sleep in hours
  "PSQI_Score" # Pittsburgh Sleep Quality Index (PSQI) Completed
  )] 
```

Define two groups: short and conventional sleepers according to the classification from Hirshkowitz et al. (2015)^[Hirshkowitz et al. (2015), National Sleep Foundation's sleep recommendations: Methodology and results summary, Sleep Health.]:

* short sleepers: average equal or less than 6 hours each night
* conventional sleepers: average between 7 and 9 hours each night

```{r}
sleep_duration = rep("undefined",nrow(subject_info))
sleep_duration[subject_info$PSQI_AmtSleep <= 6] = "short"
sleep_duration[(subject_info$PSQI_AmtSleep >= 7) & (subject_info$PSQI_AmtSleep <= 9)] = "conventional"
subject_info$sleep_duration = factor(sleep_duration)
table(subject_info$sleep_duration)
str(subject_info)
```
Load timeseries

```{r}
num_regions = as.integer(params$num_regions)
num_regions
channel_names = paste0("R",1:num_regions)
path = paste0("data/HCP_PTN820/node_timeseries/3T_HCP820_MSMAll_d",num_regions,"_ts2") 
file_names = list.files(path = path,pattern = ".txt")
file_subject_ids = strsplit(file_names,split = ".txt") %>% unlist
ts = lapply(file_subject_ids,function(Subject) {
  print(paste("reading subject:",Subject))
  full_path = paste0(path,"/",Subject,".txt")
  timeseries = read.csv(full_path,header = FALSE,sep = " ")
  timeseries$Subject = Subject
  timeseries
}) %>% do.call(rbind,.) %>% data.frame
names(ts)[1:num_regions] = channel_names
```
Merge timeseries and subject info, and separate in 2 groups. Here, "short" sleepers and "conventional" sleepers
```{r}
ts_subject_info = merge(ts,subject_info,by = "Subject")
ts_short = subset(ts_subject_info,sleep_duration=="short")
ts_short$timepoint = rep(1:(nrow(ts_short)/4),4)
ts_conventional = subset(ts_subject_info,sleep_duration=="conventional")
ts_conventional$timepoint = rep(1:(nrow(ts_conventional)/4),4)
```

## Generate our Y and X:
Y: timeseries data
X: covariate(s)

Short sleepers
```{r}
short_ids=unique(ts_short$Subject)
short_subj=subset(subject_info,sleep_duration=="short")
short_subj <- short_subj[short_subj$Subject %in% short_ids, ]
X_short_subj<-short_subj[order(short_subj$Subject),]
Y_short <- lapply(split(ts_short,ts_short$Subject), "[", TRUE, -c(17:24))
Y_short <- lapply(Y_short, "[", TRUE, -c(1))

```

Conventional sleepers
```{r}
conventional_ids=unique(ts_conventional$Subject)
conventional_subj=subset(subject_info,sleep_duration=="conventional")
conventional_subj <- conventional_subj[conventional_subj$Subject %in% conventional_ids, ]
X_conv_subj<-conventional_subj[order(conventional_subj$Subject),]
Y_conv <- lapply(split(ts_conventional,ts_conventional$Subject), "[", TRUE, -c(17:24))
Y_conv <- lapply(Y_conv, "[", TRUE, -c(1))
```


Select 1 covariate (here "PSQI_AmtSleep") and convert Y and X to matrices (required by capReg)
```{r}
X_short_subset<-subset(X_short_subj, select="PSQI_AmtSleep")
X_short_subset<-cbind(inter = 1, X_short_subset)

X_short_subset<-data.matrix(X_short_subset)
Y_short<-lapply(Y_short, function(x) data.matrix(x))
```

```{r}
X_conv_subset<-subset(X_conv_subj, select="PSQI_AmtSleep")
X_conv_subset<-cbind(inter = 1, X_conv_subset)

X_conv_subset<-data.matrix(X_conv_subset)
Y_conv<-lapply(Y_conv, function(x) data.matrix(x))
```
Center Y
```{r}
Y_c_short<- lapply(Y_short, function(x) scale(x,center = TRUE, scale = FALSE))
#Y_c_short<- lapply(Y_c_short, function(x) data.matrix(x))
Y_c_conv<- lapply(Y_conv, function(x) scale(x,center = TRUE, scale = FALSE))
#Y_c_conv<- lapply(Y_c_conv, function(x) data.matrix(x))
```
## Fit capReg

Fit of capReg, using CAP algorithm

```{r fitting cap}
fit_cap_short<-capReg(Y_c_short,X_short_subset,method="CAP")
fit_cap_conv<-capReg(Y_c_conv,X_conv_subset,method = "CAP")
```

```{r}
fit_cap_short$beta

fit_cap_conv$beta
```
Fit of capReg, using CAP-C algorithm
```{r}
fit_cap_C_short<-capReg(Y_c_short,X_short_subset,method="CAP-C")
fit_cap_C_conv<-capReg(Y_c_conv,X_conv_subset,method = "CAP-C")
```

```{r}
fit_cap_C_short$beta

fit_cap_C_conv$beta
```
Let's define treatment and control.
Treatment "by nature": short sleeper
Control: conventional sleeper

So, for short sleepers:
- Yt = values of sample covariance matrix
- Yc = predicted covariance matrix

for conventional sleepers:
- Yt = predicted covariance matrix
- Yc = sample covariance matrix

For every subject, Yt and Yc are covariance matrices (either sample or predicted)

Our covariate X is PSQI_AmtSleep = amount of sleep in hours

X=1 (treatment)
X=0 (control)

Average Causal Effect = E(Yi | Xi=1) - E(Yi | Xi=0)

For every combination of brain regions, we're performing t-test between treatment and control covariance values, for all subjects. We're performing a two-sided t-test.

So, our hypothesis test setup is the following:

H(0): The mean covariance value between 2 brain regions across all subjects is the same under treatment and under control
H(1): The mean cov. value ".." is different ".."

This translates in:
H(0): E(Yij | X=1) - E(Yij |X=0) = 0
H(1): E(Yij | X=1) - E(Yij |X=0) != 0
       
where Yij is related to i-th and j-th brain regions, i != j  (we have a test for every combination of different regions).


## Average sample covariance matrix per group of sleepers, per subject

```{r}
source("sample_covariance.R")
sample_cov_short<-sample_covariance(Y_c_short,channel_names,short_ids)
sample_cov_conventional<-sample_covariance(Y_c_conv,channel_names,conventional_ids)
```

Average covariance matrix for control group (will need for simulating data)
```{r}
avg_cov_control<-Reduce("+", sample_cov_conventional)/length(sample_cov_conventional)
```


## Covariance forcasting

Getting the Inverse of gamma*gamma' 

```{r}
source("gamma_inv.R")
gg_inv_s<-gamma_inv(fit_cap_C_short$gamma)
gg_inv_c<-gamma_inv(fit_cap_C_conv$gamma)
```

Unique X values in short and conventional and Sampling unseen X values for the 2 groups

```{r}
source("sample_unseen.R")
t_for_short<-sample_unseen(X_conv_subj$PSQI_AmtSleep,short_ids)
t_for_conv<-sample_unseen(X_short_subj$PSQI_AmtSleep,conventional_ids)

```

Try for 1st and 2nd subject from short sleepers.
```{r}
source("cov_pred_subj.R")
sig_hat_sj1<-cov_pred_subj(fit_cap_C_short$gamma,fit_cap_C_short$beta,t_for_short$X[1],gg_inv_s)
sig_hat_sj2<-cov_pred_subj(fit_cap_C_short$gamma,fit_cap_C_short$beta,t_for_short$X[2],gg_inv_s)
sig_hat_sj2<-as.matrix(sig_hat_sj2)
```


Extend to all subjects of both groups
Using function built for 1 subject, for short sleepers
```{r}
source("cov_pred_subj.R")
cov_short=list()
cov_short$cov=array(dim=c(length(channel_names),length(channel_names),length(short_ids)))
for(i in 1:length(t_for_short$X)){
  cov_short$sub[i]=t_for_short$sub[i]
  cov_short$cov[,,i]=cov_pred_subj(fit_cap_C_short$gamma,fit_cap_C_short$beta,t_for_short$X[i],gg_inv_s)
}
```


New function
```{r}
source("cov_pred.R")
cov_pred_short = cov_pred(fit_cap_C_short$gamma,fit_cap_C_short$beta,t_for_short,gg_inv_s)
cov_pred_conv = cov_pred(fit_cap_C_conv$gamma,fit_cap_C_conv$beta,t_for_conv,gg_inv_c)
```

Generate Y_t and Y_c
```{r}
ids=append(short_ids,conventional_ids)

Y_t=append(sample_cov_short,cov_pred_conv)
names(Y_t)<-ids

Y_c=append(cov_pred_short,sample_cov_conventional)
names(Y_c)<-ids
```


## Comparing

```{r}
source("get_triangle.R")
Y_t_triangle=list()
for (i in 1:length(ids)){
  Y_t_triangle[[i]]=get_triangle(Y_t[[i]])
}

Y_c_triangle=list()
for (k in 1:length(ids)){
  Y_t_triangle[[k]]=get_triangle(Y_c[[k]])
}

names(Y_t_triangle)<-ids
names(Y_c_triangle)<-ids
#names(Y_diff_triangle)<-ids

```

Corresponding elements for all subjects. Specifically: row2, col1

```{r}
tmp_Yt=vector()
for (s in 1:length(ids)){
  tmp_Yt[s]=Y_t_triangle[[s]][2,1]
}

tmp_Yc=vector()
for (s in 1:length(ids)){
  tmp_Yc[s]=Y_c_triangle[[s]][2,1]
}
```

t_test on those elements
```{r}
ttest_pairwise_1el=t.test(x=c(tmp_Yt), y=c(tmp_Yc),paired=TRUE, alternative = "two.sided")
ttest_pairwise_1el
```

Now, do the same for all matrix elements

```{r}
source("Repeated_ttest.R")
paired_ttests<-Repeated_ttest(channel_names,ids,Y_t_triangle,Y_c_triangle)

```


Prepare for BH procedure (multiple testing):

pvalues 

```{r}
source("get_pvalues.R")
list_pvalues=get_pvalues(paired_ttests)
list_pvalues=as.double(list_pvalues)
```

BH procedure
```{r}
library(stats)
BH_pvalues<-p.adjust(list_pvalues, method = "BH")
```

```{r}
p_vs_BH=tibble(list_pvalues,BH_pvalues)
p_vs_BH
```
Find highest pvalue that's also lower than the critical level

```{r}
pvsBH_reduced <- p_vs_BH[which(p_vs_BH$list_pvalues <
                                   p_vs_BH$BH_pvalues),]
pvsBH_reduced
acceptance_value=max(pvsBH_reduced$list_pvalues)
acceptance_value
```
Find accepted ones
```{r}
pv_indexed=tibble(pv=list_pvalues, index=seq(1,105))
pv_ind_ordered=pv_indexed%>%
  arrange(pv)
ranked=tibble(pv_ind_ordered,rank=seq(1,105))
ranked
```




```{r}
source("back_to_matrix.R")
BH_matrix=back_to_matrix(num_regions,channel_names,BH_pvalues)
colnames(BH_matrix)<-seq(1,15)
BH_matrix
```

```{r}
BH_df <- as.data.frame(BH_matrix)
BH_df$region_row <- seq(1,15)
BH_df <- na.omit(melt(BH_df, 'region_row', variable.name="region_col"))
BH_df$region_col <- factor(BH_df$region_col, levels=rev(levels(BH_df$region_col)))

```
```{r}
ggplot(BH_df, aes(x=region_col, y=region_row)) +
    ggtitle('Adjusted pvalues') +
    theme_bw() +
    xlab('Region') +
    ylab('Region') +
    geom_tile(aes(fill = value), color='white') +
    scale_fill_gradient(low = 'darkblue', high = 'white', space = 'Lab') +
    theme(axis.text.x=element_text(angle=90),
          axis.ticks=element_blank(),
          axis.line=element_blank(),
          panel.border=element_blank(),
          panel.grid.major=element_line(color='#eeeeee'))

```





 Need to perfect plots:
 - find nice color palette
 - add legend
 - properly tick the axes
 - choose best function  for plotting
 
 NEED TO RE-PERFORM TTEST
 


```{r}
plot_cov = function(YY,limit_value) {
  rownames(YY) = colnames(YY) = channel_names
  get_upper_tri = function(mat) {
    mat[lower.tri(mat)] = NA
    mat
  }
  YY_long = melt(get_upper_tri(YY), na.rm = TRUE)
  ggplot(data = YY_long, aes(Var2, Var1, fill = value)) +
    geom_tile(color = "white") +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                         midpoint = 0, space = "Lab",
                         limit = c(-limit_value,limit_value),
                         name = "Covariance") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          legend.position="right") +
    coord_fixed()
}
scov_short_mean = apply(scov_short$YY,MARGIN = c(2,3),FUN = mean)
scov_conventional_mean = apply(scov_conventional$YY,MARGIN = c(2,3),FUN = mean)
limit_value = max(abs(c(scov_short_mean[lower.tri(scov_short_mean)] %>% abs %>% max,
                        scov_conventional_mean[lower.tri(scov_conventional_mean)] %>% abs %>% max)))
plot_cov(scov_short_mean,limit_value)
plot_cov(scov_conventional_mean,limit_value)
```

```{r}
plot_cov = function(mat){
  #rownames(mat)=colnames(mat)=channel_names
  #mat_long=melt(mat, na.rm = TRUE)
  ggplot(data=mat, aes(region_col, region_row,fill=value))+
    geom_tile(color="white")+
    scale_fill_gradient2(low="blue", high="green", mid="white",
                         midpoint = 0.5,space="Lab",
                         name="Adjusted p-values")+
    theme_minimal()+
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          legend.position="right") +
    coord_fixed()
}

plot_cov(BH_df)
```
```{r}
abs_limit = BH_df$value %>% range
plot_try=ggplot(data = BH_df, aes(region_col, region_row, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "darkblue", high = "red", mid = "white",
                         midpoint = 0.1, space = "Lab",
                         limit = abs_limit,
                         name = "Adjusted p-values") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          legend.title=element_blank()) +
    coord_fixed() +
    ggtitle("Adjusted pvalues")

plot_try
```






















Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
